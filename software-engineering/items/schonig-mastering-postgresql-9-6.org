#+TITLE: Notes on Mastering PostgreSQL 9.6
#+AUTHOR: Bart Frenk
#+TAGS: interesting

* Meta
  Description: Notes on Schonig - Mastering PostgreSQL 9.6 (2017)
* Contents
:PROPERTIES:
:header-args+: :engine postgresql
:header-args+: :cmdline "postgresql://docker@localhost:15432/docker"
:visibility: children
:END:


** DONE Preliminaries
   CLOSED: [2018-02-07 Wed 23:10]
*** Build a docker image with PostgreSQL and curl
Create the temporary directory:
#+BEGIN_SRC shell
mkdir -p /tmp/schonig-mastering-postgresql-9-6
#+END_SRC

#+RESULTS:

Use C-c C-v t to create the Dockerfile:
#+BEGIN_SRC dockerfile :exports code :padline no :tangle /tmp/schonig-mastering-postgresql-9-6/Dockerfile
FROM postgres:9.6.2
RUN apt-get update && apt-get install -y curl
#+END_SRC

Build the docker image. This might take a while.
#+BEGIN_SRC shell
docker build -t schonig-mastering-postgresql-9-6 /tmp/schonig-mastering-postgresql-9-6/
#+END_SRC

#+RESULTS:

*** Create and start a docker container

Create and run a docker container:
#+BEGIN_SRC sh
docker run -d --name mastering-postgresql-db \
       -p 15432:5432 \
       -e POSTGRES_USER=docker \
       -e POSTGRES_DB=docker \
       schonig-mastering-postgresql-9-6
#+END_SRC

#+RESULTS:

Start Docker container:
#+BEGIN_SRC sh
docker start mastering-postgresql-db
#+END_SRC

#+RESULTS:
: mastering-postgresql-db

#+BEGIN_SRC sql
\d
#+END_SRC

#+RESULTS:
| List of relations |               |          |        |
|-------------------+---------------+----------+--------|
| Schema            | Name          | Type     | Owner  |
| public            | t_bloom       | table    | docker |
| public            | t_location    | table    | docker |
| public            | t_names       | table    | docker |
| public            | t_oil         | table    | docker |
| public            | t_test        | table    | docker |
| public            | t_test_id_seq | sequence | docker |
| public            | users         | table    | docker |

*** Seed the database

Create table and load data:
#+BEGIN_SRC sql
CREATE TABLE t_oil (
       region text,
       country text,
       year int,
       production int,
       consumption int
       );

COPY t_oil FROM PROGRAM 'curl -L www.cybertec.at/secret/oil_ext.txt ';
#+END_SRC

   #+RESULTS:
   | CREATE TABLE |
   |--------------|
   | COPY 644     |

#+BEGIN_SRC sql
SELECT COUNT(*)
FROM t_oil;
#+END_SRC

#+RESULTS:
| count |
|-------|
|   644 |


** PostgreSQL overview
   #+BEGIN_SRC sql
   SHOW max_worker_processes
   #+END_SRC

   #+RESULTS:
   | max_worker_processes |
   |----------------------|
   |                    8 |

** DONE Understanding transactions and locking
   CLOSED: [2018-03-17 Sat 23:37]
*** Working with PostgreSQL transactions
    now() returns transaction time

   #+BEGIN_SRC sql
   SELECT now(), now()
   #+END_SRC

   #+RESULTS:
   | now                         | now                         |
   |-----------------------------+-----------------------------|
   | 2018-03-13 22:17:06.6095+00 | 2018-03-13 22:17:06.6095+00 |

   #+BEGIN_SRC sql
   SELECT now();
   SELECT now()
   #+END_SRC

   #+RESULTS:
   | now                           |
   |-------------------------------|
   | 2018-03-13 22:19:25.857049+00 |
   | now                           |
   | 2018-03-13 22:19:25.857415+00 |

   For multiple statements to return the transaction time, they need to be
   started with a BEGIN statement.
   
   #+BEGIN_SRC sql
   BEGIN;
   SELECT now();
   SELECT now();
   COMMIT
   #+END_SRC

   #+RESULTS:
   | BEGIN                         |
   |-------------------------------|
   | now                           |
   | 2018-03-13 22:19:42.807131+00 |
   | now                           |
   | 2018-03-13 22:19:42.807131+00 |
   | COMMIT                        |

**** Handling errors inside a transaction
     Only error-free transactions can be committed
**** Making use of savepoints
     #+BEGIN_SRC sql
     BEGIN;
     SELECT 1;
     SAVEPOINT a;
     SELECT 2 / 0;
     ROLLBACK TO SAVEPOINT a;
     SELECT 3;
     COMMIT;
     #+END_SRC

     #+RESULTS:
     | BEGIN     |
     |-----------|
     | ?column?  |
     | 1         |
     | SAVEPOINT |
     | ROLLBACK  |
     | ?column?  |
     | 3         |
     | COMMIT    |

     The number of savepoints inside a transaction is practically unlimited.

     Point in a transaction to rollback to
**** Transactional DDLs
     
     All DDLs in PostgreSQL are transactional except:
     - DROP DATABASE
     - CREATE TABLESPACE/DROP TABLESPACE on so on
     
     #+BEGIN_SRC sql
     BEGIN;
     CREATE TABLE t_test (id int);
     ALTER TABLE t_test ALTER COLUMN id TYPE int8;
     COMMIT
     #+END_SRC

     #+RESULTS:
     | BEGIN        |
     |--------------|
     | CREATE TABLE |
     | ALTER TABLE  |
     | COMMIT       |
                   
     #+BEGIN_SRC sql
     SELECT *
     FROM pg_stat_user_tables;
     #+END_SRC

     #+RESULTS:
     | relid | schemaname | relname | seq_scan | seq_tup_read | idx_scan | idx_tup_fetch | n_tup_ins | n_tup_upd | n_tup_del | n_tup_hot_upd | n_live_tup | n_dead_tup | n_mod_since_analyze | last_vacuum | last_autovacuum | last_analyze | last_autoanalyze | vacuum_count | autovacuum_count | analyze_count | autoanalyze_count |
     |-------+------------+---------+----------+--------------+----------+---------------+-----------+-----------+-----------+---------------+------------+------------+---------------------+-------------+-----------------+--------------+------------------+--------------+------------------+---------------+-------------------|

*** Understanding basic locking
    #+BEGIN_SRC sql
    DROP TABLE t_test
    #+END_SRC

    #+RESULTS:
    | DROP TABLE |
    |------------|


    #+BEGIN_SRC sql
    CREATE TABLE t_test (id int);
    INSERT INTO t_test VALUES (1);
    #+END_SRC

    #+RESULTS:
    | CREATE TABLE |
    |--------------|
    | INSERT 0 1   |

   #+BEGIN_SRC sql
   BEGIN;
   UPDATE t_test SET id = id + 1 RETURNING *;
   COMMIT
#+END_SRC

   #+RESULTS:
   | BEGIN    |
   |----------|
   | id       |
   | 2        |
   | UPDATE 1 |
   | COMMIT   |


   - A transaction can see only those changes that have already been committed
   - Writing transactions will not block reading transactions
   - PostgreSQL will only lock rows affected by the UPDATE
**** Avoiding typical mistakes and explicit locking
*** Making use of for share and for update
    SELECT .. FOR UPDATE block each other; this allows the application to do
    read-modify-write cycles correctly. There is also SELECT .. FOR UPDATE SKIP
    LOCKED, which is not blocked, but only returns rows for which no lock is
    active.
*** Understanding transaction isolation levels
**** Phenomena defined in the SQL standard
***** dirty read
      Read a value that has not been committed yet
***** nonrepeatable read
      Reading data in a transaction twice yields different values
***** phantom read
      Selections change during transaction
***** dirty write
      Overwrite uncommitted value

**** Isolation levels (SQL)
***** READ UNCOMMITTED
      Not possible in PostgreSQL, silently mapped to READ COMMITTED.
***** READ COMMITTED
      Every statement inside a transaction will get a new snapshot of the
      data. This is the default isolation level.
***** REPEATABLE READ
      Transaction will use the same snapshot throughout the entire
      transaction. This isolation level is not more costly than READ COMMITTED.
***** SERIALIZABLE
      Transactions performed as the would be by a single client (in some order
      matching the time frames of the transactions).
*** Observing deadlocks and similar issues
    deadlocks will be resolved after the duration set in =deadlock_timeout=.
*** Utilizing advisory locks
    PostgreSQL has a function to unlock all advisory locks, =pg_advisory_unlock_all()=
*** Optimizing storage and managing cleanup
**** Configuring vacuum and autovacuum    
**** Watching vacuum at work                                    :interesting:
     Example of table size and vacuum.

     To see human-readable description of the size of 't_test'.
     #+BEGIN_SRC sql
     SELECT pg_size_pretty(pg_relation_size('t_test'));
     #+END_SRC

** DONE Making use of indexes
CLOSED: [2018-04-03 Tue 00:01]
   After 17 years of professional, full-time PostgreSQL consulting and
   PostgreSQL 24x7 support, I can say one thing for sure. Bad indexing is the
   main source of bad performance.  Of course, it is important to adjust memory
   parameters and all that. However, it is all in vain if indexes are not used
   properly. There is simply no replacement for a missing index. (p.43)
*** Understanding simple queries and the cost model

#+BEGIN_SRC sql
CREATE TABLE t_test (id serial, name text);
INSERT INTO t_test (name) SELECT 'hans'
FROM generate_series(1, 2000000);
INSERT INTO t_test (name) SELECT 'paul'
FROM generate_series(1, 2000000);
#+END_SRC

#+RESULTS:
| CREATE TABLE     |
|------------------|
| INSERT 0 2000000 |
| INSERT 0 2000000 |

#+RESULTS:

#+BEGIN_SRC sql
SELECT name, count(*) FROM t_test GROUP BY 1;
#+END_SRC

#+RESULTS:
| name |   count |
|------+---------|
| hans | 2000000 |
| paul | 2000000 |

#+BEGIN_SRC sql
ANALYZE t_test;
#+END_SRC

#+RESULTS:
| ANALYZE |
|---------|


#+BEGIN_SRC sql
EXPLAIN SELECT * FROM t_test WHERE id = 432332;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                               |
|----------------------------------------------------------|
| Seq Scan on t_test  (cost=0.00..71622.00 rows=1 width=9) |
| Filter: (id = 432332)                                    |

#+BEGIN_SRC sql
SELECT pg_relation_size('t_test') / 8192.0;
#+END_SRC

#+RESULTS:
|           ?column? |
|--------------------|
| 21622.000000000000 |

#+BEGIN_SRC sql
SHOW seq_page_cost;
SHOW cpu_tuple_cost;
SHOW cpu_operator_cost;
SHOW random_page_cost;
SHOW cpu_index_tuple_cost;
SHOW parallel_tuple_cost;
SHOW parallel_setup_cost;
SHOW min_parallel_relation_size;
#+END_SRC

#+RESULTS:
| seq_page_cost              |
|----------------------------|
| 1                          |
| cpu_tuple_cost             |
| 0.01                       |
| cpu_operator_cost          |
| 0.0025                     |
| random_page_cost           |
| 4                          |
| cpu_index_tuple_cost       |
| 0.005                      |
| parallel_tuple_cost        |
| 0.1                        |
| parallel_setup_cost        |
| 1000                       |
| min_parallel_relation_size |
| 8MB                        |

#+BEGIN_SRC python :session :exports code
21622 * 1 + 4000000 * 0.01 + 4000000 * 0.0025
#+END_SRC

#+RESULTS:
: 71622.0

#+BEGIN_SRC sql
CREATE INDEX idx_id ON t_test (id);
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|

#+BEGIN_SRC sql
EXPLAIN SELECT * FROM t_test WHERE id = 432332;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                          |
|---------------------------------------------------------------------|
| Index Scan using idx_id on t_test  (cost=0.43..8.45 rows=1 width=9) |
| Index Cond: (id = 432332)                                           |

#+BEGIN_SRC sql
SELECT relname,
       reltuples,
       pg_size_pretty(relpages::bigint * 8 * 1024) AS size
FROM pg_class
WHERE relname = 'idx_id'
ORDER BY relpages DESC;
#+END_SRC

#+RESULTS:
| relname | reltuples | size  |
|---------+-----------+-------|
| idx_id  |     4e+06 | 86 MB |

B-tree indexes are not only useful to find rows. They are also useful to feed
sorted data to the next stage in the process:

#+BEGIN_SRC sql
EXPLAIN SELECT * FROM t_test ORDER BY id DESC LIMIT 10;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                                  |
|---------------------------------------------------------------------------------------------|
| Limit  (cost=0.43..125505.43 rows=4000000 width=9)                                          |
| ->  Index Scan Backward using idx_id on t_test  (cost=0.43..125505.43 rows=4000000 width=9) |



**** WAIT Read the article on concurrent B-trees
See [5].
*** Improving speed using clustered tables
**** Clustering tables
The =CLUSTER= commands allows one to rewrite tables in the order of some
index. This might speed up queries. However:
1. the =CLUSTER= command will lock the table for writing,
2. the clustered state will not be maintained, need to do this regularly.
**** Making use of index only scans

#+BEGIN_SRC sql
EXPLAIN ANALYZE SELECT * FROM t_test where id = 34234;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                                                    |
|---------------------------------------------------------------------------------------------------------------|
| Index Scan using idx_id on t_test  (cost=0.43..8.45 rows=1 width=9) (actual time=0.009..0.009 rows=1 loops=1) |
| Index Cond: (id = 34234)                                                                                      |
| Planning time: 0.177 ms                                                                                       |
| Execution time: 0.032 ms                                                                                      |

#+BEGIN_SRC sql
EXPLAIN ANALYZE SELECT id FROM t_test where id = 34234;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                                                         |
|--------------------------------------------------------------------------------------------------------------------|
| Index Only Scan using idx_id on t_test  (cost=0.43..8.45 rows=1 width=4) (actual time=0.015..0.015 rows=1 loops=1) |
| Index Cond: (id = 34234)                                                                                           |
| Heap Fetches: 1                                                                                                    |
| Planning time: 0.171 ms                                                                                            |
| Execution time: 0.040 ms                                                                                           |

*Conclusion*: There does not seem to be much difference between an index scan
and an index only scan.

*** Understanding additional B-tree features
Takeaways from this chapter.
1. Order matters for combined indexes (this is not new information)
2. One can also index on the result of a function (this is not new information)
3. Indexing can be expensive in terms of space consumption (use =\di+= displays
   space usage of indices, and =\d+= displays space usage of tables).
4. Normally you cannot modify a table while an index is being built, use CREATE
   INDEX CONCURRENTLY to allow modifications while building an index. Note that
   this operation might fail.

*** Introducing operator classes
It is possible to use a custom order for B-tree indices. The mechanism by which
to do so is called an operator class. This section defines one for social
security numbers.

Accordingly, the particular operators with which a GiST index can be used vary
depending on the indexing strategy (the operator class). As an example, the
standard distribution of PostgreSQL includes GiST operator classes for several
two-dimensional geometric data types, ... <from the [[https://www.postgresql.org/docs/9.2/static/indexes-types.html][PostgreSQL manual]]>
*** Understanding PostgreSQL index types
**** Hash indexes
Do not use them as:
1. they have no support for concurrency,
2. and do not work well with the transaction log
**** GiST indexes
More complex index family.

Use cases for GiST indexes:
1. range types
2. geometric indexes
3. fuzzy searching

The explanation in the book is half-hearted and vague. 
***** WAIT Write your own operator class for a GiST index
Start with this section. There are some pointers on how to implement B-tree
indexes using GiST.
**** GIN indexes
We follow this [[https://hashrocket.com/blog/posts/exploring-postgres-gin-index][Hashrocket blog post]] for some additional information on GIN
indexes. They are useful for full text search. See the section on full text
search.

***** Hashrocket blog post
#+BEGIN_SRC sql
CREATE TABLE users (
       first_name text,
       last_name text
)
#+END_SRC

#+RESULTS:
| CREATE TABLE |
|--------------|

#+BEGIN_SRC sql
INSERT INTO users
SELECT md5(random()::text), md5(random()::text)
FROM generate_series(1, 1000000)
#+END_SRC

#+RESULTS:
| INSERT 0 1000000 |
|------------------|

#+BEGIN_SRC sql
SELECT * FROM users LIMIT 10;
#+END_SRC

#+RESULTS:
| first_name                       | last_name                        |
|----------------------------------+----------------------------------|
| a0ba7243f50f00f4573ba75e8e1589b3 | 7c2e1ac7bde261ff00910d2d42d0b776 |
| 2eb0aeefae47a8d5878181a06c0ba451 | 96753c7b8d8dc5ec61eb7c3207a0df2d |
| 679142fb39459e78716eecbc49eb4fb2 | 5a7eba0270f9880f39f1a0343320b9c8 |
| b13f93cd46310dde473cd610839dc9c5 | 60b41f3331b91de7d388451015f993fe |
| efbe4c5e4a1ceb9c3a6ed5e09b07877f | 93ecca4e085e5d6137a3b73da3f61357 |
| 8d54e947d7f08f971198a67169d3bd24 | 7717571c5b75066946bf77305a819015 |
| 54d49bc3f7265a19e0aa7005f042ecc8 | 262ebc439f0e887a1330c9c1a087e794 |
| 70eaa5de69144e77a7e259ae4d61a5ad | 4a369aafec92628dc35ad02df0e1067e |
| e6b98032892a734b24c481c66699ad6a | a901221461e8da4ac89bc21d96397a88 |
| 8cdf6c102624ab432c381e31d188af45 | 8632f8f0d0478ffeab9bb2e9a192c48f |

#+NAME: ilike_first_name
#+BEGIN_SRC sql
EXPLAIN ANALYSE SELECT count(*) FROM users WHERE first_name ilike '%aeb%'
#+END_SRC

#+RESULTS: ilike_first_name
| QUERY PLAN                                                                                                                  |
|-----------------------------------------------------------------------------------------------------------------------------|
| Aggregate  (cost=395.28..395.29 rows=1 width=8) (actual time=18.946..18.946 rows=1 loops=1)                                 |
| ->  Bitmap Heap Scan on users  (cost=20.77..395.03 rows=100 width=0) (actual time=2.112..18.456 rows=7335 loops=1)          |
| Recheck Cond: (first_name ~~* '%aeb%'::text)                                                                                |
| Heap Blocks: exact=5546                                                                                                     |
| ->  Bitmap Index Scan on users_search_idx  (cost=0.00..20.75 rows=100 width=0) (actual time=1.296..1.296 rows=7335 loops=1) |
| Index Cond: (first_name ~~* '%aeb%'::text)                                                                                  |
| Planning time: 0.927 ms                                                                                                     |
| Execution time: 19.099 ms                                                                                                   |

#+NAME: ilike_both
#+BEGIN_SRC sql
EXPLAIN ANALYSE SELECT count(*) FROM users WHERE first_name ilike '%aeb%' OR last_name ilike '%aeb%'
#+END_SRC

#+RESULTS: ilike_both
| QUERY PLAN                                                                                                                  |
|-----------------------------------------------------------------------------------------------------------------------------|
| Aggregate  (cost=765.31..765.32 rows=1 width=8) (actual time=37.249..37.249 rows=1 loops=1)                                 |
| ->  Bitmap Heap Scan on users  (cost=41.60..764.81 rows=200 width=0) (actual time=3.815..36.390 rows=14378 loops=1)         |
| Recheck Cond: ((first_name ~~* '%aeb%'::text) OR (last_name ~~* '%aeb%'::text))                                             |
| Heap Blocks: exact=8562                                                                                                     |
| ->  BitmapOr  (cost=41.60..41.60 rows=200 width=0) (actual time=2.472..2.472 rows=0 loops=1)                                |
| ->  Bitmap Index Scan on users_search_idx  (cost=0.00..20.75 rows=100 width=0) (actual time=1.310..1.310 rows=7335 loops=1) |
| Index Cond: (first_name ~~* '%aeb%'::text)                                                                                  |
| ->  Bitmap Index Scan on users_search_idx  (cost=0.00..20.75 rows=100 width=0) (actual time=1.162..1.162 rows=7082 loops=1) |
| Index Cond: (last_name ~~* '%aeb%'::text)                                                                                   |
| Planning time: 0.995 ms                                                                                                     |
| Execution time: 37.415 ms                                                                                                   |

#+BEGIN_SRC sql
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX users_search_idx
ON users
USING gin (first_name gin_trgm_ops,
           last_name gin_trgm_ops)
#+END_SRC

#+RESULTS:
| CREATE EXTENSION |
|------------------|
| CREATE INDEX     |


| GIN index | Query            | Estimated cost | Execution time |
|-----------+------------------+----------------+----------------|
| No        | ilike_first_name |       24846.26 | 957.001 ms     |
| No        | ilike_both       |       27346.51 | 1892.734 ms    |
| Yes       | ilike_first_name |         395.29 | 18.843 ms      |
| Yes       | ilike_both       |         765.32 | 59.019 ms      |

#+BEGIN_SRC sql
CREATE INDEX users_search_idx_btree ON users (first_name)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|


#+BEGIN_SRC sql
SELECT pg_size_pretty(pg_relation_size('users_search_idx')) as users_search_idx,
       pg_size_pretty(pg_relation_size('users')) as users,
       pg_size_pretty(pg_relation_size('users_search_idx_btree')) as users_search_idx_btree
#+END_SRC

#+RESULTS:
| users_search_idx | users | users_search_idx_btree |
|------------------+-------+------------------------|
| 237 MB           | 96 MB | 56 MB                  |

**** SP-GiST indexes
More complex index family.

Mainly been designed for in-memory use. They can be used to implement various
types of trees, such as quadtrees, k-d trees and radix trees (tries).
**** BRIN indexes

Characteristics of BRIN indexes:
1. very small,
2. but lossy

It will store the minimum and maximum values for blocks of data.

#+BEGIN_SRC sql
CREATE INDEX idx_id_brin ON t_test USING brin(id);
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|

#+BEGIN_SRC sql
CREATE INDEX idx_id on t_test (id)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|


#+BEGIN_SRC sql
SELECT pg_size_pretty(pg_relation_size('idx_id_brin')) as idx_id_brin,
       pg_size_pretty(pg_relation_size('idx_id')) as idx_id
#+END_SRC

#+RESULTS:
| idx_id_brin | idx_id |
|-------------+--------|
| 24 kB       | 86 MB  |

#+BEGIN_SRC sql
DROP INDEX IF EXISTS idx_id
#+END_SRC

#+RESULTS:
| DROP INDEX |
|------------|

#+BEGIN_SRC sql
DROP INDEX IF EXISTS idx_id_brin
#+END_SRC

#+RESULTS:
| DROP INDEX |
|------------|


#+BEGIN_SRC sql
EXPLAIN ANALYZE SELECT * FROM t_test WHERE id = 12345;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                                                    |
|---------------------------------------------------------------------------------------------------------------|
| Index Scan using idx_id on t_test  (cost=0.43..8.45 rows=1 width=9) (actual time=0.028..0.028 rows=1 loops=1) |
| Index Cond: (id = 12345)                                                                                      |
| Planning time: 0.233 ms                                                                                       |
| Execution time: 0.052 ms                                                                                      |

| Index  | Estimated cost | Method            | Execution time |
|--------+----------------+-------------------+----------------|
| None   |          71622 | Seq Scan          | 336.013 ms     |
| B-tree |           8.45 | Index Scan        | 0.052 ms       |
| BRIN   |          16.02 | Bitmap Index Scan | 4.192 ms       |

**** Adding additional indexes
Talks about bloom filters and how to access them from PostgreSQL. For the actual
theory the book refers to the [[https://en.wikipedia.org/wiki/Bloom_filter][Wikipedia]] entry on Bloom filters.

Quite useful when there are a large number of columns that are all eligible for
indexing.

Requires an extension:
#+BEGIN_SRC sql
CREATE EXTENSION bloom;
#+END_SRC

#+RESULTS:
| CREATE EXTENSION |
|------------------|

#+BEGIN_SRC sql
DROP TABLE IF EXISTS t_bloom;
CREATE TABLE t_bloom (x1 int, x2 int, x3 int, x4 int, x5 int, x6 int, x7 int)
#+END_SRC

#+RESULTS:
| DROP TABLE   |
|--------------|
| CREATE TABLE |

#+BEGIN_SRC sql
CREATE INDEX idx_bloom ON t_bloom (x1, x2, x3, x4, x5, x6, x7)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|

#+BEGIN_SRC sql
DROP INDEX IF EXISTS idx_bloom;
#+END_SRC

#+RESULTS:
| DROP INDEX |
|------------|

#+BEGIN_SRC sql
CREATE INDEX idx_bloom_btree_x1 ON t_bloom(x1)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|



#+BEGIN_SRC sql
INSERT INTO t_bloom
SELECT floor(random() * 1000) AS x1,
       floor(random() * 1000) AS x2,
       floor(random() * 1000) AS x3,
       floor(random() * 1000) AS x4,
       floor(random() * 1000) AS x5,
       floor(random() * 1000) AS x6,
       floor(random() * 1000) AS x7
FROM generate_series(1, 100000);
#+END_SRC

#+RESULTS:
| INSERT 0 100000 |
|-----------------|

#+BEGIN_SRC sql
EXPLAIN SELECT * FROM t_bloom WHERE x1 = 42 AND 1000 <= x3 AND x3 < 2000;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                    |
|-------------------------------------------------------------------------------|
| Index Only Scan using idx_bloom on t_bloom  (cost=0.42..9.64 rows=1 width=28) |
| Index Cond: ((x1 = 42) AND (x3 >= 1000) AND (x3 < 2000))                      |

#+BEGIN_SRC sql
EXPLAIN SELECT * FROM t_bloom WHERE x1 = 42;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                     |
|--------------------------------------------------------------------------------|
| Bitmap Heap Scan on t_bloom  (cost=5.04..276.68 rows=97 width=28)              |
| Recheck Cond: (x1 = 42)                                                        |
| ->  Bitmap Index Scan on idx_bloom_btree_x1  (cost=0.00..5.02 rows=97 width=0) |
| Index Cond: (x1 = 42)                                                          |


#+BEGIN_SRC sql
SELECT pg_size_pretty(pg_relation_size('idx_bloom')) AS idx_bloom,
       pg_size_pretty(pg_relation_size('idx_bloom_btree_x1')) AS idx_bloom_btree_x1
#+END_SRC

#+RESULTS:
| idx_bloom | idx_bloom_btree_x1 |
|-----------+--------------------|
| 4880 kB   | 2208 kB            |

*** Achieving better answers with fuzzy searching
**** Taking advantage of pg_trgm
***** Install extension

#+BEGIN_SRC sql
CREATE EXTENSION pg_trgm
#+END_SRC

#+RESULTS:
| CREATE EXTENSION |
|------------------|

***** Seed database

#+BEGIN_SRC sql
CREATE TABLE t_location (name text)
#+END_SRC

#+RESULTS:
| CREATE TABLE |
|--------------|

#+BEGIN_SRC sql
COPY t_location FROM PROGRAM 'curl -L www.cybertec.at/secret/orte.txt'
#+END_SRC

#+RESULTS:
| COPY 2354 |
|-----------|

***** Experiment with pg_trgm

#+BEGIN_SRC sql
SELECT 'abcde' <-> 'abdeacb'
#+END_SRC

#+RESULTS:
| ?column? |
|----------|
| 0.833333 |

#+NAME: trigrams-abcde
#+BEGIN_SRC sql
SELECT show_trgm('abcde')
#+END_SRC

#+RESULTS:
| show_trgm                       |
|---------------------------------|
| {"  a"," ab",abc,bcd,cde,"de "} |

#+NAME: trigrams-abdeacb
#+BEGIN_SRC sql
SELECT show_trgm('abdeacb')
#+END_SRC

#+RESULTS:
| show_trgm                               |
|-----------------------------------------|
| {"  a"," ab",abd,acb,bde,"cb ",dea,eac} |

#+BEGIN_SRC emacs-lisp :var table=trigrams-abcde[2, 0]
(print table)
#+END_SRC

#+RESULTS:
: {"  a"," ab",abc,bcd,cde,"de "}

#+BEGIN_SRC sql
SELECT * FROM t_location ORDER BY name <-> 'Kramertneusiedel' LIMIT 3;
#+END_SRC

#+RESULTS:
| name           |
|----------------|
| Gramatneusiedl |
| Klein-Neusiedl |
| Potzneusiedl   |

***** Compare pg_trgm GiST index on a small table

#+BEGIN_SRC sql
SELECT count(*) FROM t_location;
#+END_SRC

#+RESULTS:
| count |
|-------|
|  2354 |

Create B-tree index on name to compare with GiST index:
#+BEGIN_SRC sql
CREATE INDEX idx_name ON t_location (name)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|

Compare index and relation sizes:
#+BEGIN_SRC sql
SELECT pg_size_pretty(pg_relation_size('idx_trgm')) as idx_trgm,
       pg_size_pretty(pg_relation_size('idx_name')) as idx_name,
       pg_size_pretty(pg_relation_size('t_location')) as t_location
#+END_SRC

#+RESULTS:
| idx_trgm | idx_name | t_location |
|----------+----------+------------|
| 200 kB   | 96 kB    | 112 kB     |

#+NAME: with-idx_trgm
#+BEGIN_SRC sql
CREATE INDEX idx_trgm ON t_location USING GiST(name GiST_trgm_ops);
EXPLAIN SELECT * FROM t_location ORDER BY name <-> 'Kramertneusiedel' LIMIT 3;
#+END_SRC

#+NAME: without-idx_trgm
#+BEGIN_SRC sql
DROP INDEX IF EXISTS idx_trgm; 
EXPLAIN SELECT * FROM t_location ORDER BY name <-> 'Kramertneusiedel' LIMIT 3;
#+END_SRC

#+NAME: exact-name
#+BEGIN_SRC sql
EXPLAIN SELECT * FROM t_location WHERE name = 'Gramatneusiedl';
#+END_SRC

#+RESULTS: with-idx_trgm
| CREATE INDEX                                                                        |
|-------------------------------------------------------------------------------------|
| QUERY PLAN                                                                          |
| Limit  (cost=0.14..0.40 rows=3 width=17)                                            |
| ->  Index Scan using idx_trgm on t_location  (cost=0.14..203.22 rows=2354 width=17) |
| Order By: (name <-> 'Kramertneusiedel'::text)                                       |

#+RESULTS: without-idx_trgm
| DROP INDEX                                                        |
|-------------------------------------------------------------------|
| QUERY PLAN                                                        |
| Limit  (cost=73.85..73.86 rows=3 width=17)                        |
| ->  Sort  (cost=73.85..79.74 rows=2354 width=17)                  |
| Sort Key: ((name <-> 'Kramertneusiedel'::text))                   |
| ->  Seq Scan on t_location  (cost=0.00..43.42 rows=2354 width=17) |

#+RESULTS: exact-name
| QUERY PLAN                                                                      |
|---------------------------------------------------------------------------------|
| Index Only Scan using idx_name on t_location  (cost=0.28..8.30 rows=1 width=13) |
| Index Cond: (name = 'Gramatneusiedl'::text)                                     |

***** Compare trigram GiST index on larger table

****** Create function to generate random string

Create a function to generate random strings. From this [[http://www.simononsoftware.com/random-string-in-postgresql/][blog post]].
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION random_text(length INTEGER)
RETURNS TEXT
LANGUAGE PLPGSQL
AS $$ 
DECLARE 
  cs TEXT := concat('0123456789',
                    'ABCDEFGHIJKLMNOPQRSTUVWXYZ',
                    'abcdefghijklmnopqrstuvwxyz'); 
  res TEXT := '';
  i INT4;
  n INTEGER; 
BEGIN
  n := length(cs);
  FOR i IN 1..length LOOP 
    res := res || substr(cs, (1 + FLOOR((n + 1) * random() ))::INTEGER, 1);
  END LOOP;
  RETURN res;
END; $$;
#+END_SRC

#+RESULTS:
| CREATE FUNCTION |
|-----------------|

#+BEGIN_SRC sql
SELECT random_text(10);
#+END_SRC

#+RESULTS:
| random_text |
|-------------|
| lF7jhITRpd  |

****** Set up database

Create a table with a single bounded text column:

#+BEGIN_SRC sql
DROP TABLE IF EXISTS t_names;
CREATE TABLE t_names (name varchar(255))
#+END_SRC

#+RESULTS:
| DROP TABLE   |
|--------------|
| CREATE TABLE |

Create a trigram-based GiST index:

#+BEGIN_SRC sql
CREATE INDEX idx_name_trgm ON t_names USING GiST(name GiST_trgm_ops)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|

Create a B-tree index for comparison:

#+BEGIN_SRC sql
CREATE INDEX idx_name_btree ON t_names (name)
#+END_SRC

#+RESULTS:
| CREATE INDEX |
|--------------|

****** Perform the experiment

List the sizes of all object under consideration:

#+BEGIN_SRC sql
SELECT pg_size_pretty(pg_relation_size('idx_name_trgm')) as idx_name_trgm,
       pg_size_pretty(pg_relation_size('t_names')) as t_names,
       pg_size_pretty(pg_relation_size('idx_name_btree')) as idx_name_btree;
#+END_SRC

#+RESULTS:
| idx_name_trgm | t_names | idx_name_btree |
|---------------+---------+----------------|
| 83 MB         | 29 MB   | 32 MB          |

Insert 100K random strings of length 42 in the table, and return the total count:

#+BEGIN_SRC sql
INSERT INTO t_names
SELECT random_text(42)
FROM generate_series(1, 100000);
SELECT COUNT(*) FROM t_names;
#+END_SRC

#+RESULTS:
| INSERT 0 100000 |
|-----------------|
| count           |
| 400000          |

Select the closest words:

#+BEGIN_SRC sql
EXPLAIN SELECT name FROM t_names ORDER BY 'HelloWorld' <-> name LIMIT 50;
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                                |
|-------------------------------------------------------------------------------------------|
| Limit  (cost=0.41..8.60 rows=50 width=46)                                                 |
| ->  Index Scan using idx_name_trgm on t_names  (cost=0.41..65564.41 rows=400000 width=46) |
| Order By: ((name)::text <-> 'HelloWorld'::text)                                           |

Select a precise word:

#+BEGIN_SRC sql
EXPLAIN SELECT name FROM t_names WHERE name = 'HelloWorld';
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                         |
|------------------------------------------------------------------------------------|
| Index Only Scan using idx_name_btree on t_names  (cost=0.42..8.44 rows=1 width=42) |
| Index Cond: (name = 'HelloWorld'::text)                                            |

****** Conclusion
Selecting the $n$ closest words gets to be more expensive when $n$ is around 50,
when there are 400K random words in the database of length 42. Here, random
means that each letter of the word is selected uniformly at random from the set
of digits, upper-case and lower-case letters.

**** Speeding up LIKE queries; handling regular expressions
Makes use of the tables creating in the previous two items.

#+BEGIN_SRC sql
EXPLAIN ANALYZE SELECT *
FROM t_location
WHERE name LIKE '%neu%'
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                                                      |
|-----------------------------------------------------------------------------------------------------------------|
| Bitmap Heap Scan on t_location  (cost=4.33..19.05 rows=24 width=13) (actual time=0.338..0.385 rows=13 loops=1)  |
| Recheck Cond: (name ~~ '%neu%'::text)                                                                           |
| Rows Removed by Index Recheck: 48                                                                               |
| Heap Blocks: exact=12                                                                                           |
| ->  Bitmap Index Scan on idx_trgm  (cost=0.00..4.32 rows=24 width=0) (actual time=0.322..0.322 rows=61 loops=1) |
| Index Cond: (name ~~ '%neu%'::text)                                                                             |
| Planning time: 0.237 ms                                                                                         |
| Execution time: 0.903 ms                                                                                        |

#+BEGIN_SRC sql
CREATE INDEX idx_trgm ON t_location USING GiST(name GiST_trgm_ops);
EXPLAIN SELECT *
FROM t_location
WHERE name ~ '[A-C].*neu.*'
#+END_SRC

#+RESULTS:
| QUERY PLAN                                                                 |
|----------------------------------------------------------------------------|
| Index Scan using idx_trgm on t_location  (cost=0.14..8.16 rows=1 width=13) |
| Index Cond: (name ~ '[A-C].*neu.*'::text)                                  |

#+BEGIN_SRC sql
DROP INDEX idx_trgm;
EXPLAIN SELECT *
FROM t_location
WHERE name ~ '[A-C].*neu.*'
#+END_SRC

#+RESULTS:
| DROP INDEX                                                 |
|------------------------------------------------------------|
| QUERY PLAN                                                 |
| Seq Scan on t_location  (cost=0.00..43.42 rows=1 width=13) |
| Filter: (name ~ '[A-C].*neu.*'::text)                      |


Compute the expected number of words (out of =word_cnt= words) having a random
infix of size =infix_sz=. This should be the average number of rows returned
from the query above, when one varies =neu= over sequences of the same length.
#+BEGIN_SRC python :session :exports code
alph_sz = 10 + 26 + 26
word_sz = 42
infix_sz = 3
word_cnt = 400000

rem_sz = word_sz - infix_sz
p =  (rem_sz + 1) * (alph_sz ** rem_sz) / (alph_sz ** word_sz)

{"expected count": word_cnt * p, "probability": p}
#+END_SRC

#+RESULTS:
| expected count | : | 67.13436944043504 | probability | : | 0.00016783592360108759 |

*** Understanding full-text search - FTS

Find words and apply transformations.
#+BEGIN_SRC sql
SELECT to_tsvector('english',
                   'A car, I want a car. I would not even mind having many cars')
#+END_SRC

#+RESULTS:
| to_tsvector                                                   |
|---------------------------------------------------------------|
| 'car':2,6,14 'even':10 'mani':13 'mind':11 'want':4 'would':8 |


Figure out which configurations (e.g., =english= in the query above) are supported.
#+BEGIN_SRC sql
SELECT cfgname FROM pg_ts_config;
#+END_SRC

#+RESULTS:
| cfgname    |
|------------|
| simple     |
| danish     |
| dutch      |
| english    |
| finnish    |
| french     |
| german     |
| hungarian  |
| italian    |
| norwegian  |
| portuguese |
| romanian   |
| russian    |
| spanish    |
| swedish    |
| turkish    |

** DONE Handling advanced SQL
   CLOSED: [2018-02-07 Wed 23:09]
*** GROUPING SETS, CUBE, ROLLUP
   
    #+BEGIN_SRC sql
    SELECT region, country, avg(production)
    FROM t_oil
    WHERE country IN ('USA', 'Canada', 'Iran', 'Oman')
    GROUP BY CUBE (region, country)
    #+END_SRC

    #+RESULTS:
    | region        | country |                   avg |
    |---------------+---------+-----------------------|
    | Middle East   | Iran    | 3631.6956521739130435 |
    | Middle East   | Oman    |  586.4545454545454545 |
    | Middle East   |         | 2142.9111111111111111 |
    | North America | Canada  | 2123.2173913043478261 |
    | North America | USA     | 9141.3478260869565217 |
    | North America |         | 5632.2826086956521739 |
    |               |         | 3906.7692307692307692 |
    |               | Canada  | 2123.2173913043478261 |
    |               | Iran    | 3631.6956521739130435 |
    |               | Oman    |  586.4545454545454545 |
    |               | USA     | 9141.3478260869565217 |

    #+BEGIN_SRC sql
    EXPLAIN ANALYZE SELECT region, sum(production)
    FROM t_oil
    GROUP BY region
    #+END_SRC

    #+RESULTS:
    | QUERY PLAN                                                                                              |
    |---------------------------------------------------------------------------------------------------------|
    | HashAggregate  (cost=15.66..15.68 rows=2 width=20) (actual time=0.222..0.222 rows=2 loops=1)            |
    | Group Key: region                                                                                       |
    | ->  Seq Scan on t_oil  (cost=0.00..12.44 rows=644 width=16) (actual time=0.006..0.054 rows=644 loops=1) |
    | Planning time: 0.126 ms                                                                                 |
    | Execution time: 0.284 ms                                                                                |

    #+BEGIN_SRC sql
    EXPLAIN ANALYZE SELECT region, country, sum(production)
    FROM t_oil
    GROUP BY ROLLUP (region, country)
    #+END_SRC

    #+RESULTS:
    | QUERY PLAN                                                                                              |
    |---------------------------------------------------------------------------------------------------------|
    | GroupAggregate  (cost=42.49..49.24 rows=31 width=24) (actual time=0.392..0.522 rows=17 loops=1)         |
    | Group Key: region, country                                                                              |
    | Group Key: region                                                                                       |
    | Group Key: ()                                                                                           |
    | ->  Sort  (cost=42.49..44.10 rows=644 width=24) (actual time=0.377..0.401 rows=644 loops=1)             |
    | Sort Key: region, country                                                                               |
    | Sort Method: quicksort  Memory: 75kB                                                                    |
    | ->  Seq Scan on t_oil  (cost=0.00..12.44 rows=644 width=24) (actual time=0.004..0.085 rows=644 loops=1) |
    | Planning time: 0.180 ms                                                                                 |
    | Execution time: 0.570 ms                                                                                |

    #+BEGIN_SRC sql
    EXPLAIN (ANALYZE, TIMING, BUFFERS, COSTS) SELECT sum(production)
    FROM t_oil
    #+END_SRC

    #+RESULTS:
    | QUERY PLAN                                                                                             |
    |--------------------------------------------------------------------------------------------------------|
    | Aggregate  (cost=14.05..14.06 rows=1 width=4) (actual time=0.118..0.118 rows=1 loops=1)                |
    | Buffers: shared hit=6                                                                                  |
    | ->  Seq Scan on t_oil  (cost=0.00..12.44 rows=644 width=4) (actual time=0.007..0.044 rows=644 loops=1) |
    | Buffers: shared hit=6                                                                                  |
    | Planning time: 0.124 ms                                                                                |
    | Execution time: 0.150 ms                                                                               |

    #+BEGIN_SRC sql
    CREATE INDEX country_idx
    ON t_oil (country)
    #+END_SRC

    #+RESULTS:
    | CREATE INDEX |
    |--------------|

    #+BEGIN_SRC sql
    DROP INDEX country_idx;
    #+END_SRC

    #+RESULTS:
    | DROP INDEX |
    |------------|


    #+BEGIN_SRC sql
    EXPLAIN SELECT region, country, sum(production) as production
    FROM t_oil
    GROUP BY GROUPING SETS ((), region, country);
    #+END_SRC

    #+RESULTS:
    | QUERY PLAN                                                  |
    |-------------------------------------------------------------|
    | GroupAggregate  (cost=42.49..82.53 rows=17 width=24)        |
    | Group Key: region                                           |
    | Group Key: ()                                               |
    | Sort Key: country                                           |
    | Group Key: country                                          |
    | ->  Sort  (cost=42.49..44.10 rows=644 width=24)             |
    | Sort Key: region                                            |
    | ->  Seq Scan on t_oil  (cost=0.00..12.44 rows=644 width=24) |

*** FILTER

    #+BEGIN_SRC sql
    SELECT
        region,
        sum(production) AS total,
        sum(production) FILTER (WHERE year < 1990) AS old,
        sum(production) FILTER (WHERE year >= 1990) AS new
    FROM t_oil
    GROUP BY ROLLUP (region)
    #+END_SRC

    #+RESULTS:
    | region        |   total |    old |    new |
    |---------------+---------+--------+--------|
    | Middle East   |  864790 | 391401 | 473389 |
    | North America |  626708 | 335374 | 291334 |
    |               | 1491498 | 726775 | 764723 |


    Note that if it is possible to move conditions to a WHERE clause it is
    always more desirable as less data has to be fetched from the table. FILTER
    is only useful if the data left by the WHERE clause is not needed by each
    aggregate. (p.96)


*** Making use of ordered sets: mode, percentile_disc, percentile_cont
    
    #+BEGIN_SRC sql
    SELECT region,
           percentile_disc(0.5) WITHIN GROUP (ORDER BY production) AS median,
           percentile_cont(0.5) WITHIN GROUP (ORDER BY production) AS interpolated
    FROM t_oil
    GROUP BY 1;
    #+END_SRC

    #+RESULTS:
    | region        | median | interpolated |
    |---------------+--------+--------------|
    | Middle East   |   1082 |         1094 |
    | North America |   3054 |       3066.5 |

    #+BEGIN_SRC sql
    SELECT percentile_disc(0.5) WITHIN GROUP (ORDER BY x) as median,
           percentile_cont(0.5) WITHIN GROUP (ORDER BY x) as interpolated
    FROM generate_series(0, 1) as x
    #+END_SRC

    #+RESULTS:
    | median | interpolated |
    |--------+--------------|
    |      0 |          0.5 |

*** Hypothetical aggregates

    #+BEGIN_SRC sql :exports code
    SELECT country,
           rank(9000) WITHIN GROUP (ORDER BY production DESC NULLS LAST)
    FROM t_oil
    GROUP BY ROLLUP (country);
    #+END_SRC

    #+RESULTS:
    | country              | rank |
    |----------------------+------|
    | Canada               |    1 |
    | Iran                 |    1 |
    | Iraq                 |    1 |
    | Israel               |    1 |
    | Kuwait               |    1 |
    | Mexico               |    1 |
    | Oman                 |    1 |
    | Other Middle East    |    1 |
    | Qatar                |    1 |
    | Saudi Arabien        |   21 |
    | Syria                |    1 |
    | United Arab Emirates |    1 |
    | USA                  |   27 |
    | Yemen                |    1 |
    |                      |   47 |

*** Windowing queries
**** Partitioning data


     #+BEGIN_SRC sql
     SELECT distinct(year < 1990, avg(production) OVER (PARTITION BY year < 1990))
     FROM t_oil
     #+END_SRC

     #+RESULTS:
     | row                       |
     |---------------------------|
     | (f,2801.1831501831501832) |
     | (t,2430.6856187290969900) |

     Better with a filter condition (the query plan is much less complex, and
     the query is more efficient)

     #+BEGIN_SRC sql
     SELECT
         avg(production) FILTER (WHERE year < 1990) as old,
         avg(production) FILTER (WHERE year >= 1990) as new
     FROM t_oil
     #+END_SRC

     #+RESULTS:
     |                   old |                   new |
     |-----------------------+-----------------------|
     | 2430.6856187290969900 | 2801.1831501831501832 |


     - the number of rows returned doesn't change (unlike with GROUP BY)
     - ordering within a partition matters for aggregation

    #+BEGIN_SRC sql :exports code
    SELECT country,
           year,
           production,
           consumption,
           avg(production) OVER (PARTITION BY country)
    FROM t_oil
    LIMIT 10;
    #+END_SRC

    #+RESULTS:
    | country | year | production | consumption |                   avg |
    |---------+------+------------+-------------+-----------------------|
    | Canada  | 1965 |        920 |        1108 | 2123.2173913043478261 |
    | Canada  | 2010 |       3332 |        2316 | 2123.2173913043478261 |
    | Canada  | 2009 |       3202 |        2190 | 2123.2173913043478261 |
    | Canada  | 2008 |       3207 |        2315 | 2123.2173913043478261 |
    | Canada  | 2007 |       3290 |        2361 | 2123.2173913043478261 |
    | Canada  | 2006 |       3208 |        2295 | 2123.2173913043478261 |
    | Canada  | 2005 |       3040 |        2288 | 2123.2173913043478261 |
    | Canada  | 2004 |       3079 |        2309 | 2123.2173913043478261 |
    | Canada  | 2003 |       3003 |        2228 | 2123.2173913043478261 |
    | Canada  | 2002 |       2858 |        2172 | 2123.2173913043478261 |

    #+BEGIN_SRC sql :exports code
    SELECT country,
           year,
           production,
           min(production) OVER (),
           min(production) OVER (ORDER BY year)
    FROM t_oil
    WHERE year BETWEEN 1978 AND 1983
          AND country = 'Iran';
    #+END_SRC

**** Using sliding windows

     This is a clear query to show the results of sliding windows.

     #+BEGIN_SRC sql :exports code
     SELECT *,
            array_agg(id) OVER (ORDER BY id ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)
     FROM generate_series(1, 5) as id;
     #+END_SRC

     #+RESULTS:
     | id | array_agg |
     |----+-----------|
     |  1 | {1,2}     |
     |  2 | {1,2,3}   |
     |  3 | {2,3,4}   |
     |  4 | {3,4,5}   |
     |  5 | {4,5}     |

     - Can be unbounded on both sides by UNBOUNDED FOLLOWING, or UNBOUNDED PRECEDING

**** Abstracting window clauses
     You can name your window clauses using a WINDOW clause, as in the query
     below

     #+BEGIN_SRC sql
     SELECT region, country,
            year,
            production,
            min(production) OVER (w),
            max(production) OVER (w)
     FROM t_oil
     WHERE region = 'North America' AND year BETWEEN 1980 AND 1985
     WINDOW w AS (PARTITION BY country ORDER BY year)
     #+END_SRC

     #+RESULTS:
     | region        | country | year | production |   min |   max |
     |---------------+---------+------+------------+-------+-------|
     | North America | Canada  | 1980 |       1764 |  1764 |  1764 |
     | North America | Canada  | 1981 |       1610 |  1610 |  1764 |
     | North America | Canada  | 1982 |       1590 |  1590 |  1764 |
     | North America | Canada  | 1983 |       1661 |  1590 |  1764 |
     | North America | Canada  | 1984 |       1775 |  1590 |  1775 |
     | North America | Canada  | 1985 |       1812 |  1590 |  1812 |
     | North America | Mexico  | 1980 |       2129 |  2129 |  2129 |
     | North America | Mexico  | 1981 |       2553 |  2129 |  2553 |
     | North America | Mexico  | 1982 |       3001 |  2129 |  3001 |
     | North America | Mexico  | 1983 |       2930 |  2129 |  3001 |
     | North America | Mexico  | 1984 |       2942 |  2129 |  3001 |
     | North America | Mexico  | 1985 |       2912 |  2129 |  3001 |
     | North America | USA     | 1980 |      10170 | 10170 | 10170 |
     | North America | USA     | 1981 |      10181 | 10170 | 10181 |
     | North America | USA     | 1982 |      10199 | 10170 | 10199 |
     | North America | USA     | 1983 |      10247 | 10170 | 10247 |
     | North America | USA     | 1984 |      10509 | 10170 | 10509 |
     | North America | USA     | 1985 |      10580 | 10170 | 10580 |

**** Various functions
     Windowing works with all aggregate functions, and additionaly:
     - rank
     - dense_rank
     - ntile
     - lead
     - lag
     - first_value
     - nth_value
     - last_value
     - row_number
       
     #+BEGIN_SRC sql
     SELECT year, production,
            ntile(4) OVER (ORDER BY production)
     FROM t_oil
     WHERE country = 'Iraq' AND year BETWEEN 2000 AND 2006
     #+END_SRC

     #+RESULTS:
     | year | production | ntile |
     |------+------------+-------|
     | 2003 |       1344 |     1 |
     | 2005 |       1833 |     1 |
     | 2006 |       1999 |     2 |
     | 2004 |       2030 |     2 |
     | 2002 |       2116 |     3 |
     | 2001 |       2522 |     3 |
     | 2000 |       2613 |     4 |

     #+BEGIN_SRC sql
     SELECT region, country, year, production,
            rank() OVER (PARTITION BY region ORDER BY production DESC NULLS LAST)
     FROM t_oil
     WHERE year = 2010
     ORDER BY region, rank
     #+END_SRC

     #+RESULTS:
     | region        | country              | year | production | rank |
     |---------------+----------------------+------+------------+------|
     | Middle East   | Saudi Arabien        | 2010 |      10007 |    1 |
     | Middle East   | Iran                 | 2010 |       4352 |    2 |
     | Middle East   | United Arab Emirates | 2010 |       2895 |    3 |
     | Middle East   | Kuwait               | 2010 |       2562 |    4 |
     | Middle East   | Iraq                 | 2010 |       2490 |    5 |
     | Middle East   | Qatar                | 2010 |       1655 |    6 |
     | Middle East   | Oman                 | 2010 |        865 |    7 |
     | Middle East   | Syria                | 2010 |        385 |    8 |
     | Middle East   | Yemen                | 2010 |        306 |    9 |
     | Middle East   | Other Middle East    | 2010 |        192 |   10 |
     | Middle East   | Israel               | 2010 |            |   11 |
     | North America | USA                  | 2010 |       7513 |    1 |
     | North America | Canada               | 2010 |       3332 |    2 |
     | North America | Mexico               | 2010 |       2959 |    3 |


*** Writing your own aggregates
    Writing aggregates is not hard and it can be highly beneficial to perform
    more complex operations. In this section the plan is to write a hypothetical
    aggregate, which has already been discussed in this chapter (p.120)

    #+BEGIN_SRC sql :exports code
    CREATE FUNCTION taxi_per_line (numeric, numeric)
    RETURN numeric AS
    $$
    BEGIN
    RAISE NOTICE 'intermediate: %, per row: %', $1, $2;
    RETURN $1 + $2 * 2.2;
    END;
    $$ LANGUAGE 'plpgsql';
    #+END_SRC

    #+RESULTS:

    #+BEGIN_SRC sql :exports code
    CREATE AGGREGATE taxi_price (numeric)
    (
        INITCOND = 2.5,
        SFUNC = taxi_per_line,
        STYPE = numeric
    );
    #+END_SRC

    #+RESULTS    

    One can optimize the aggregate functions to be more efficient when using
    with sliding windows. Think recursive filters. How to starts at page 118.

*** Random experiments

    #+BEGIN_SRC sql
    SELECT *
    FROM pg_catalog.pg_tables
    WHERE tablename = 't_oil';
    #+END_SRC

    #+RESULTS:
    | schemaname | tablename | tableowner | tablespace | hasindexes | hasrules | hastriggers | rowsecurity |
    |------------+-----------+------------+------------+------------+----------+-------------+-------------|
    | public     | t_oil     | bart       |            | f          | f        | f           | f           |

    #+BEGIN_SRC sql
    CREATE INDEX region_country_idx
    ON t_oil (region, country);
    #+END_SRC

    #+RESULTS:
    | CREATE INDEX |
    |--------------|


    #+BEGIN_SRC sql
    SELECT region,
           country,
           sum(production) as production,
           sum(consumption) as consumption
    FROM t_oil
    WHERE country IN ('USA', 'Canada', 'Iran', 'Oman')
    GROUP BY ROLLUP (region, country);
    #+END_SRC

    #+RESULTS:
    | region        | country | production | consumption |
    |---------------+---------+------------+-------------|
    | Middle East   | Iran    |     167058 |       44894 |
    | Middle East   | Oman    |      25804 |             |
    | Middle East   |         |     192862 |       44894 |
    | North America | Canada  |      97668 |       82728 |
    | North America | USA     |     420502 |      794365 |
    | North America |         |     518170 |      877093 |
    |               |         |     711032 |      921987 |

** DONE Log files and system statistics
CLOSED: [2018-05-31 Thu 23:34]

*** Checkig live traffic
#+BEGIN_SRC sql
\d pg_stat_activity
#+END_SRC

#+RESULTS:
| View "pg_catalog.pg_stat_activity" |                          |           |
|------------------------------------+--------------------------+-----------|
| Column                             | Type                     | Modifiers |
| datid                              | oid                      |           |
| datname                            | name                     |           |
| pid                                | integer                  |           |
| usesysid                           | oid                      |           |
| usename                            | name                     |           |
| application_name                   | text                     |           |
| client_addr                        | inet                     |           |
| client_hostname                    | text                     |           |
| client_port                        | integer                  |           |
| backend_start                      | timestamp with time zone |           |
| xact_start                         | timestamp with time zone |           |
| query_start                        | timestamp with time zone |           |
| state_change                       | timestamp with time zone |           |
| wait_event_type                    | text                     |           |
| wait_event                         | text                     |           |
| state                              | text                     |           |
| backend_xid                        | xid                      |           |
| backend_xmin                       | xid                      |           |
| query                              | text                     |           |

#+BEGIN_SRC sql :results value table replace
\x
SELECT pid, application_name, state, query FROM pg_stat_activity
#+END_SRC

#+RESULTS:
| pid              | 100                                                              |
|------------------+------------------------------------------------------------------|
| application_name | psql                                                             |
| state            | active                                                           |
| query            | select pg_sleep(1000);                                           |
|                  |                                                                  |
| pid              | 104                                                              |
| application_name | psql                                                             |
| state            | active                                                           |
| query            | SELECT pid, application_name, state, query FROM pg_stat_activity |

Cancel a query.
#+BEGIN_SRC sql
SELECT pg_cancel_backend(100)
#+END_SRC

#+RESULTS:
| pg_cancel_backend |
|-------------------|
| t                 |

Cancel a query and terminate the connection
#+BEGIN_SRC sql
SELECT pg_terminate_backend(100);
#+END_SRC


*** Inspecting databases
#+BEGIN_SRC sql
\d pg_stat_database
#+END_SRC

#+RESULTS:
| View "pg_catalog.pg_stat_database" |                          |           |
|------------------------------------+--------------------------+-----------|
| Column                             | Type                     | Modifiers |
| datid                              | oid                      |           |
| datname                            | name                     |           |
| numbackends                        | integer                  |           |
| xact_commit                        | bigint                   |           |
| xact_rollback                      | bigint                   |           |
| blks_read                          | bigint                   |           |
| blks_hit                           | bigint                   |           |
| tup_returned                       | bigint                   |           |
| tup_fetched                        | bigint                   |           |
| tup_inserted                       | bigint                   |           |
| tup_updated                        | bigint                   |           |
| tup_deleted                        | bigint                   |           |
| conflicts                          | bigint                   |           |
| temp_files                         | bigint                   |           |
| temp_bytes                         | bigint                   |           |
| deadlocks                          | bigint                   |           |
| blk_read_time                      | double precision         |           |
| blk_write_time                     | double precision         |           |
| stats_reset                        | timestamp with time zone |           |

#+BEGIN_SRC sql
\x
SELECT * FROM pg_stat_database
#+END_SRC

#+RESULTS:
| datid          |                         12407 |
|----------------+-------------------------------|
| datname        |                      postgres |
| numbackends    |                             0 |
| xact_commit    |                           715 |
| xact_rollback  |                             0 |
| blks_read      |                           391 |
| blks_hit       |                         27929 |
| tup_returned   |                        348577 |
| tup_fetched    |                          5968 |
| tup_inserted   |                             0 |
| tup_updated    |                             7 |
| tup_deleted    |                             0 |
| conflicts      |                             0 |
| temp_files     |                             0 |
| temp_bytes     |                             0 |
| deadlocks      |                             0 |
| blk_read_time  |                             0 |
| blk_write_time |                             0 |
| stats_reset    | 2018-04-02 13:41:51.621048+00 |
|                |                               |
| datid          |                         16384 |
| datname        |                        docker |
| numbackends    |                             2 |
| xact_commit    |                          1445 |
| xact_rollback  |                            61 |
| blks_read      |                        163021 |
| blks_hit       |                      12201322 |
| tup_returned   |                      48377835 |
| tup_fetched    |                        174069 |
| tup_inserted   |                       5527685 |
| tup_updated    |                            20 |
| tup_deleted    |                           177 |
| conflicts      |                             0 |
| temp_files     |                            13 |
| temp_bytes     |                     449219904 |
| deadlocks      |                             0 |
| blk_read_time  |                             0 |
| blk_write_time |                             0 |
| stats_reset    | 2018-04-02 13:43:20.999935+00 |
|                |                               |
| datid          |                             1 |
| datname        |                     template1 |
| numbackends    |                             0 |
| xact_commit    |                             0 |
| xact_rollback  |                             0 |
| blks_read      |                             0 |
| blks_hit       |                             0 |
| tup_returned   |                             0 |
| tup_fetched    |                             0 |
| tup_inserted   |                             0 |
| tup_updated    |                             0 |
| tup_deleted    |                             0 |
| conflicts      |                             0 |
| temp_files     |                             0 |
| temp_bytes     |                             0 |
| deadlocks      |                             0 |
| blk_read_time  |                             0 |
| blk_write_time |                             0 |
| stats_reset    |                               |
|                |                               |
| datid          |                         12406 |
| datname        |                     template0 |
| numbackends    |                             0 |
| xact_commit    |                             0 |
| xact_rollback  |                             0 |
| blks_read      |                             0 |
| blks_hit       |                             0 |
| tup_returned   |                             0 |
| tup_fetched    |                             0 |
| tup_inserted   |                             0 |
| tup_updated    |                             0 |
| tup_deleted    |                             0 |
| conflicts      |                             0 |
| temp_files     |                             0 |
| temp_bytes     |                             0 |
| deadlocks      |                             0 |
| blk_read_time  |                             0 |
| blk_write_time |                             0 |
| stats_reset    |                               |

*** Making sense of ps_stat_user_tables                       :interesting:
*** Digging into indexes
#+BEGIN_SRC sql
SELECT
schemaname,
indexrelid,
relname,
indexrelname,
idx_scan,
pg_size_pretty(pg_relation_size(indexrelid)),
pg_size_pretty(sum(pg_relation_size(indexrelid))
OVER (ORDER BY idx_scan, indexrelid)) AS total
FROM
pg_stat_user_indexes
ORDER BY total
#+END_SRC

#+RESULTS:
| schemaname | indexrelid | relname    | indexrelname           | idx_scan | pg_size_pretty | total  |
|------------+------------+------------+------------------------+----------+----------------+--------|
| public     |      16505 | t_test     | idx_id                 |        1 | 86 MB          | 181 MB |
| public     |      16486 | t_names    | idx_name_trgm          |        8 | 83 MB          | 264 MB |
| public     |      16487 | t_names    | idx_name_btree         |        0 | 32 MB          | 32 MB  |
| public     |      16506 | t_test     | idx_id_brin            |        0 | 24 kB          | 32 MB  |
| public     |      16526 | t_bloom    | idx_bloom              |        0 | 4880 kB        | 37 MB  |
| public     |      16527 | t_bloom    | idx_bloom_btree_x1     |        0 | 2208 kB        | 39 MB  |
| public     |      16536 | users      | users_search_idx       |       16 | 237 MB         | 501 MB |
| public     |      16537 | users      | users_search_idx_btree |        0 | 56 MB          | 95 MB  |
| public     |      16468 | t_location | idx_name               |        0 | 96 kB          | 96 kB  |

*** Using pg_stat_statements

** DONE Optimizing queries for good performance
   CLOSED: [2018-01-02 Tue 15:15]
*** Optimization strategies
    - constant folding
    - view inlining
    - join reordering
    - flattening subselects
    - join pruning
    - applying equality constraints
    - function inlining
    - distribute over set operations (UNION [ALL], etc.)
    
    It is not difficult to make the process fail (e.g. by specifying OFFSET =
    0). Always run explain on a query.
*** Preliminaries
    Taken from [1].

*** Relevant system catalogs
    pg_class catalogs tables and most everything else that has columns or is
      otherwise similar to a table.
    - pg_stats is a view on top of pg_statistics
    - pg_statistics stores statistical data about the contents of the database
    - pg_stat_user_tables contains one row for each table in the current database,
      showing statistics about accesses to that specific table

*** Node types in a query plan
**** Scans
***** Index-Only Scan
      - Only needs to fetch index pages
      - Requires data to be fetched to be available from the index
      - MVCC visibility information is not stored in the index, but the table's
        visibility map has a flag for each heap page that indicates when an
        entire page is old enough to be visible to all current and future
        transactions. (see [2], Chapter 11.11 Index-Only Scans)
***** Index Scan
      - Rows are fetched in index order from the index, and then separately
        retrieved from the heap
***** Seq Scan
      - Entire table is scanned
***** Bitmap Heap Scan
      - Used after a Bitmap Index Scan, retrieves the pages selected by the Bitmap Index Scan
      - Needs to apply the filter condition again, since rows in the heap page
        fetched might not satisfy it.
***** Bitmap Index Scan
      - Gathers the pages of the rows to retrieved from the index
***** Function Scan
**** Joins
***** Hash Join
      - The rows of one of the tables are collected in a hash table (which one is indicated by Hash)
      - These rows are then looked up from the row set of the other table
***** Merge Join
      - Requires the tables to be sorted on fields in the join condition
      - Merging then takes time proportional to the number sum of the rows of
        the tables to merge.
***** Nested Loop
      - A nested loop takes time proportional to the products of the number of
        rows to merge.
**** Miscellaneous
***** Append
      - Appends to result sets
***** Unique
      - Filter out duplicates
      - Can be expensive (see [0], p. 163)
***** Sort
      - Sort the result set
****** external sort Disk
****** quicksort Memory
****** top-N heapsort Memory
       - To only provide top-n rows
***** Limit
      - Limits the result set
***** Subquery Scan

**** Aggregates
***** HashAggregate
      - Aggregate by building an in-memory hash table
***** GroupAggregate
      - Requires sorted data
      - Takes linear time, but can emit partial results

*** Understanding execution plans: Spotting problems

    Some relevant quotes from the PostgreSQL manual:

    The most critical part of the display is the estimated statement execution
    cost, which is the planner's guess at how long it will take to run the
    statement (measured in cost units that are arbitrary, but conventionally
    mean disk page fetches). Actually two numbers are shown: the start-up cost
    before the first row can be returned, and the total cost to return all the
    rows.

    The ANALYZE option causes the statement to be actually executed, not only
    planned. Then actual run time statistics are added to the display, including
    the total elapsed time expended within each plan node (in milliseconds) and
    the total number of rows it actually returned. This is useful for seeing
    whether the planner's estimates are close to reality.



    - Start where the query times jump
    - Inspect estimates
      - Maybe row sizes are over- or under-estimated due to wrong statistics
      - Maybe cross-column correlations make the estimates off (statistics in
        PostgreSQL 9.6 are univariate).
    - Inspect buffer usage

*** Miscellaneous notes

**** CLUSTER clauses
     - Rewrite the table in the same order as a (B-tree) index ([0],
       p. 170). Requires a table lock.

**** Inner joins may be reordered
     - Outer joins cannot always be reordered
     - This is probably a restatement of the algebraic properties of both of
       these types of joins in the relational algebra.

**** GROUP BY 1
     - It is possible to specify only the indices of the column to group or
       order by.

*** Partitioning data

**** Modifying inherited structure
     - Adding and removing columns propagates to the child tables
     - Adding indexes *does not*
     - It is also simple to change the parent of the child table. Maybe for
       moving data from active to history.

*** Adjusting parameters

**** work_mem
     - Query plans obviously depend on working memory.

**** maintenance_work_mem
     - Memory available for maintenance work (creating indices, etc.). Not so
       useful, maybe for creating indices on the fly.
    
** DONE Writing stored procedures
   CLOSED: [2018-01-02 Tue 15:15]
*** Takeaways
    - Probably better to use the jv8 extension that allows for using JavaScript
      in PostgreSQL as a trusted language. Also pglpsql seems quite simple.
**** Triggers are useful and flexible
     - They run in alphabetical order!
**** Types of functions
     - volatile: no assumptions on return value
     - stable: referentially transparent within a transaction
     - immutable: referentially transparent
**** PL/pgSQL is simple and takes care of more things
     - For example, caching execution plans (see [0], p.228).
**** Can create your own operators, type casts, and even collations
     - Collation is combining data, but I think refers mostly to sort orders in
       this context.
*** JavaScript is also available as trusted language
    See [3] and [4] for the full matrix of available programming languages.
** Managing PostgreSQL security
** Handling backup and recovery
** Making sense of backups and replication
** STARTED Deciding on useful extensions
#+BEGIN_SRC sql
SELECT *
FROM pg_available_extensions;
#+END_SRC

#+RESULTS:
| name               | default_version | installed_version | comment                                                              |
|--------------------+-----------------+-------------------+----------------------------------------------------------------------|
| btree_gin          |             1.0 |                   | support for indexing common datatypes in GIN                         |
| sslinfo            |             1.2 |                   | information about SSL certificates                                   |
| chkpass            |             1.0 |                   | data type for auto-encrypted passwords                               |
| tablefunc          |             1.0 |                   | functions that manipulate whole tables, including crosstab           |
| intagg             |             1.1 |                   | integer aggregator and enumerator (obsolete)                         |
| file_fdw           |             1.0 |                   | foreign-data wrapper for flat file access                            |
| tcn                |             1.0 |                   | Triggered change notifications                                       |
| refint             |             1.0 |                   | functions for implementing referential integrity (obsolete)          |
| bloom              |             1.0 |               1.0 | bloom access method - signature file based index                     |
| hstore             |             1.4 |                   | data type for storing sets of (key, value) pairs                     |
| adminpack          |             1.0 |                   | administrative functions for PostgreSQL                              |
| pg_freespacemap    |             1.1 |                   | examine the free space map (FSM)                                     |
| dict_xsyn          |             1.0 |                   | text search dictionary template for extended synonym processing      |
| pg_visibility      |             1.1 |                   | examine the visibility map (VM) and page-level visibility info       |
| pg_buffercache     |             1.2 |                   | examine the shared buffer cache                                      |
| lo                 |             1.1 |                   | Large Object maintenance                                             |
| btree_gist         |             1.2 |                   | support for indexing common datatypes in GiST                        |
| pgcrypto           |             1.3 |                   | cryptographic functions                                              |
| earthdistance      |             1.1 |                   | calculate great-circle distances on the surface of the Earth         |
| pg_trgm            |             1.3 |               1.3 | text similarity measurement and index searching based on trigrams    |
| fuzzystrmatch      |             1.1 |                   | determine similarities and distance between strings                  |
| tsm_system_rows    |             1.0 |                   | TABLESAMPLE method which accepts number of rows as a limit           |
| cube               |             1.2 |                   | data type for multidimensional cubes                                 |
| moddatetime        |             1.0 |                   | functions for tracking last modification time                        |
| uuid-ossp          |             1.1 |                   | generate universally unique identifiers (UUIDs)                      |
| plpgsql            |             1.0 |               1.0 | PL/pgSQL procedural language                                         |
| intarray           |             1.2 |                   | functions, operators, and index support for 1-D arrays of integers   |
| pg_prewarm         |             1.1 |                   | prewarm relation data                                                |
| tsearch2           |             1.0 |                   | compatibility package for pre-8.3 text search functions              |
| dblink             |             1.2 |                   | connect to other PostgreSQL databases from within a database         |
| unaccent           |             1.1 |                   | text search dictionary that removes accents                          |
| autoinc            |             1.0 |                   | functions for autoincrementing fields                                |
| postgres_fdw       |             1.0 |                   | foreign-data wrapper for remote PostgreSQL servers                   |
| isn                |             1.1 |                   | data types for international product numbering standards             |
| xml2               |             1.1 |                   | XPath querying and XSLT                                              |
| pageinspect        |             1.5 |                   | inspect the contents of database pages at a low level                |
| ltree              |             1.1 |                   | data type for hierarchical tree-like structures                      |
| dict_int           |             1.0 |                   | text search dictionary template for integers                         |
| pgstattuple        |             1.4 |                   | show tuple-level statistics                                          |
| pg_stat_statements |             1.4 |                   | track execution statistics of all SQL statements executed            |
| tsm_system_time    |             1.0 |                   | TABLESAMPLE method which accepts time in milliseconds as a limit     |
| timetravel         |             1.0 |                   | functions for implementing time travel                               |
| pgrowlocks         |             1.2 |                   | show row-level locking information                                   |
| insert_username    |             1.0 |                   | functions for tracking who changed a table                           |
| citext             |             1.3 |                   | data type for case-insensitive character strings                     |
| seg                |             1.1 |                   | data type for representing line segments or floating-point intervals |

** Troubleshooting PostgreSQL
** Migrating to PostgreSQL
* Extras
  :PROPERTIES:
  :engine:   postgresql
  :cmdline: "-U bart"
  :exports: both
  :visibility: folded
  :END:
  Benchmarking partitioned versus unpartitioned tables
** Partitioned

   #+BEGIN_SRC sql
   drop table p_stats cascade;

   create table p_stats (
     adset_id integer not null,
     hour integer not null,
     views integer not null,
     primary key (adset_id, hour, views)
   );


   create table p_stats_0 () inherits (p_stats);
   create table p_stats_1 () inherits (p_stats);
   create table p_stats_2 () inherits (p_stats);
   create table p_stats_3 () inherits (p_stats);
   create table p_stats_4 () inherits (p_stats);
   create table p_stats_5 () inherits (p_stats);
   create table p_stats_6 () inherits (p_stats);
   create table p_stats_7 () inherits (p_stats);
   create table p_stats_8 () inherits (p_stats);
   create table p_stats_9 () inherits (p_stats);


   alter table p_stats_0 add check (hour < 1000000);
   alter table p_stats_1 add check (hour >= 1000000 and hour < 2000000);
   alter table p_stats_2 add check (hour >= 2000000 and hour < 3000000);
   alter table p_stats_3 add check (hour >= 3000000 and hour < 4000000);
   alter table p_stats_4 add check (hour >= 4000000 and hour < 5000000);
   alter table p_stats_5 add check (hour >= 5000000 and hour < 6000000);
   alter table p_stats_6 add check (hour >= 6000000 and hour < 7000000);
   alter table p_stats_7 add check (hour >= 7000000 and hour < 8000000);
   alter table p_stats_8 add check (hour >= 8000000 and hour < 9000000);
   alter table p_stats_9 add check (hour >= 9000000 and hour < 10000000);


   insert into p_stats_0 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(0, 999999) s;

   insert into p_stats_1 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(1000000, 1999999) s;


   insert into p_stats_2 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(2000000, 2999999) s;


   insert into p_stats_3 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(3000000, 3999999) s;


   insert into p_stats_4 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(4000000, 4999999) s;


   insert into p_stats_5 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(5000000, 5999999) s;


   insert into p_stats_6 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(6000000, 6999999) s;


   insert into p_stats_7 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(7000000, 7999999) s;


   insert into p_stats_8 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(8000000, 8999999) s;


   insert into p_stats_9 (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(9000000, 9999999) s;




   #+END_SRC


** Non-partitioned
   #+BEGIN_SRC sql
   drop table stats;

   create table stats (
     adset_id integer not null,
     hour integer not null,
     views integer not null,
     primary key (adset_id, hour, views)
   );

   insert into stats (adset_id, hour, views)
   select 1, s, s % 100
   from generate_series(1, 10000000) s;

   #+END_SRC

* References
[0] Schonig - Mastering PostgreSQL 9.6
[1] https://www.postgresql.org/docs/9.6/static/using-explain.html
[2] https://www.postgresql.org/docs/9.6/
[3] https://github.com/plv8/plv8
[4] https://wiki.postgresql.org/wiki/PL_Matrix
[5] Lehman, Yao. Efficient locking for concurrent operations on
B-trees (1981). https://www.csd.uoc.gr/~hy460/pdf/p650-lehman.pdf
[6] Fairly useful summary of the PostgreSQL cost
model. http://shiroyasha.io/the-postgresql-query-cost-model.html
