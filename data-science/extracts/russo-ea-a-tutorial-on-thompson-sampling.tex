% Created 2018-04-20 Fri 13:35
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\usepackage{amsmath}
\usepackage{paralist}
\usepackage[utf8]{inputenc}
\usepackage{palatino}
\usepackage{euler}
\usepackage{setspace}
\renewcommand{\em}[1]{\textbf{#1}}
\newcommand{\E}[1]{\operatorname{\mathbb{E}}[#1]}
\setstretch{1.1}
\let\itemize\compactitem
\let\description\compactdesc
\let\enumerate\compactenum
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\newcommand{\RR}{\mathbb{R}}
\author{Bart Frenk}
\date{\today}
\title{Notes on A tutorial on Thompson sampling}
\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 25.1.1 (Org mode 8.2.10)}}
\begin{document}

\maketitle


\section{Tutorial on Thompson sampling}
\label{sec-1}
\subsection{Introduction}
\label{sec-1-1}
\subsection{Greedy decisions}
\label{sec-1-2}
\subsection{Thompson sampling for the Bernoulli bandit}
\label{sec-1-3}
\subsection{General Thompson sampling}
\label{sec-1-4}
\subsection{Approximations}
\label{sec-1-5}
Waiting on background on Laplace approximations.

Approximations are not so useful, since computation time grows with the size of
the size of the history.

In order to keep the computational burden manageable, it can be important to
consider incremental variants of our approximation methods. We refer to an
algorithm as \textbf{incremental} if it operates with \textbf{fixed} rather than growing
per-period compute time. There are many ways to design incremental variants of
approximate posterior sampling algorithms we have presented. As concrete
examples, we consider here particular incremental versions of Laplace
approximation and bootstrap approaches. (p.19)

\subsection{Practical modeling considerations}
\label{sec-1-6}
\subsection{Further examples}
\label{sec-1-7}
\subsection{Why it work, when it fails, and alternative approaches}
\label{sec-1-8}


\section{An empirical evaluation of Thompson sampling}
\label{sec-2}
Article published in \textbf{december 2011}.

Has the example of optimizing the CTR of an ad display campaign. They use a
Laplace approximation of the posterior, and a logistic regression model to
relate context to CTRs. Very similar to what we might do. Has quite some
references to articles dealing with display ad campaigns.


\subsection{Notes}
\label{sec-2-1}

\subsubsection{Introduction}
\label{sec-2-1-1}

\begin{quote}
In this work, we present some empirical results, first on a simulated problem
and then on two real-world ones: display advertisement selection and news
article recommendation. In all cases, despite its simplicity, Thompson sampling
achieves state-of-the-art results, and in some cases significantly outperforms
other alternatives like UCB. The findings suggest the necessity to include
Thompson sampling as part of the standard baselines to compare against, and to
develop finite-time regret bound for this empirically successful
algorithm. (p.1)
\end{quote}

\subsubsection{Algorithms}
\label{sec-2-1-2}

\begin{description}
\item[{Upper confidence bound (UCB)}] Strong theoretical guarantees on the
regret. There are various variants of the UCB algorithm, but they all have
in common that the confidence parameter should increase over time. (p.2)
\item[{Bayes-optimal approach of Gittins}] Directly maximizes expected cumulative
payoffs with respect to a given prior distribution.
\item[{Probability matching (Thompson sampling)}] Heuristic (\textbf{from 1933})
\end{description}

Write
\[
Q(a, x, r) = \mathbb{I}\Big(\E{r \mid a, x, \theta} = max_{a'} \E{r \mid a', x, \theta}\Big)
\]

I find it easier to understand the expression

\[
\int Q(a, x, r) \, P(\theta \mid D) d\theta
\]

by considering the (hypothetical) case in which there is exactly one $\theta'$
such that $Q(a, x, r)$ is $1$. The expression then reduces to $P(\theta' | D)$,
which is exactly the probability that $a$ is the action with the expected
maximal reward.

\subsubsection{Simulations}
\label{sec-2-1-3}

\begin{quote}
We can thus conclude that in these simulations, Thompson sampling is
asymptotically optimal and achieves a smaller regret than the popular UCB
algorithm. It is important to note that for UCB, the confidence bound (1) is
tight; we have tried some other confidence bounds, including the one originally
proposed in \footnote{Weinberger, ea. Feature hashing for large scale multitask learning.}, but they resulted in larger regrets. (p.4)
\end{quote}

\textbf{Optimistic Thompson selecting}

For an action $a$:

\begin{enumerate}
\item Draw $\theta'$ from the posterior.
\item Compute the expected reward for $a$ conditional on $\theta'$.
\item Compute the expected reward for $a$, unconditionally.
\item Take the maximum of step 2. and 3.
\end{enumerate}

This results in a marginally better regret in the simulations. The difference is
small.

\textbf{Posterior reshaping}

Widen the variance, by having a posterior with parameters $a/\alpha$ and $b / \alpha$.

\subsubsection{Display advertising}
\label{sec-2-1-4}

\begin{quote}
In this paper, we consider standard regularized logistic regression for
predicting CTR. There are several features representing the user, page, ad, as
well as conjunctions of these features. Some of the features include identifiers
of the ad, advertiser, publisher and visited page. These features are
hashed and each training sample ends up being represented as sparse binary
vector of dimension $2^{24}$. (p.5)
\end{quote}

They use the Laplace approximation of the posterior, in the following sense:
\begin{enumerate}
\item The Laplace approximation of the posterior is used as an approximation to the
prior in the next Bayesian update step.
\item Instead of sampling from the posterior, they sample from the Laplace
approximation to the posterior.
\end{enumerate}

I think they use some type of per-period regret, since the regret is decreasing
over time. Could not find how long the period was.

Note that clicks are simulated based on weight parameters estimated from real
data.

They have 13000 contexts per hour; the number of eligible ads varies between
5,910 and 1, with a mean of 1,364 and a median of 514.

\begin{verbatim}
return 13000 / 3600
\end{verbatim}

\begin{verbatim}
3.611111111111111
\end{verbatim}

I think they use a single logistic regression model, with input features derived
from a (context, ad) pair, i.e.,

\[
\E{Y|X=x, A=a} = \sigma(h(x, a))
\]







\begin{enumerate}
\item Look into feature hashing
\label{sec-2-1-4-1}

Start here: Why feature hashing? They link to an article \footnotemark[1]{}.
\end{enumerate}


\section{Extra}
\label{sec-3}

\subsection{Bounds}
\label{sec-3-1}
Mentioned in \textbf{An emperical evaluation of Thompson sampling}.

\begin{description}
\item[{Chernoff bound}] 
\item[{Markov inequality}] 
\item[{Chebyshev bound}] 
\end{description}
% Emacs 25.1.1 (Org mode 8.2.10)
\end{document}